{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3866368,"sourceType":"datasetVersion","datasetId":849073}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebook951b0d6a22?scriptVersionId=193087929\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:13:42.850262Z","iopub.execute_input":"2024-08-18T14:13:42.85106Z","iopub.status.idle":"2024-08-18T14:13:47.272349Z","shell.execute_reply.started":"2024-08-18T14:13:42.851021Z","shell.execute_reply":"2024-08-18T14:13:47.271396Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/fruit-recognition/train/train'\ndataset = datasets.ImageFolder(root=data_dir)\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:13:47.274218Z","iopub.execute_input":"2024-08-18T14:13:47.274933Z","iopub.status.idle":"2024-08-18T14:13:51.656697Z","shell.execute_reply.started":"2024-08-18T14:13:47.274902Z","shell.execute_reply":"2024-08-18T14:13:51.655689Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"16854"},"metadata":{}}]},{"cell_type":"code","source":"dataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:13:51.65801Z","iopub.execute_input":"2024-08-18T14:13:51.658384Z","iopub.status.idle":"2024-08-18T14:13:51.664848Z","shell.execute_reply.started":"2024-08-18T14:13:51.658351Z","shell.execute_reply":"2024-08-18T14:13:51.663684Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['Apple Braeburn',\n 'Apple Granny Smith',\n 'Apricot',\n 'Avocado',\n 'Banana',\n 'Blueberry',\n 'Cactus fruit',\n 'Cantaloupe',\n 'Cherry',\n 'Clementine',\n 'Corn',\n 'Cucumber Ripe',\n 'Grape Blue',\n 'Kiwi',\n 'Lemon',\n 'Limes',\n 'Mango',\n 'Onion White',\n 'Orange',\n 'Papaya',\n 'Passion Fruit',\n 'Peach',\n 'Pear',\n 'Pepper Green',\n 'Pepper Red',\n 'Pineapple',\n 'Plum',\n 'Pomegranate',\n 'Potato Red',\n 'Raspberry',\n 'Strawberry',\n 'Tomato',\n 'Watermelon']"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_ratio = 0.8\n\ntrain_data, test_data = random_split(dataset, [train_ratio, 1-train_ratio])","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:13:51.667088Z","iopub.execute_input":"2024-08-18T14:13:51.667403Z","iopub.status.idle":"2024-08-18T14:13:51.701282Z","shell.execute_reply.started":"2024-08-18T14:13:51.667378Z","shell.execute_reply":"2024-08-18T14:13:51.700428Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.RandomHorizontalFlip(p=0.5), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) \n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.3517, 0.3557, 0.3570],\n                         std=[0.2325, 0.2347, 0.2353]) \n])\n\n\nclass TransformDataset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n        \n    def __len__(self):\n        return len(self.subset)\n\n    \ntrain_data = TransformDataset(train_data, transform = train_transform)\ntest_data = TransformDataset(test_data, transform = test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:13:51.702209Z","iopub.execute_input":"2024-08-18T14:13:51.702486Z","iopub.status.idle":"2024-08-18T14:13:51.712136Z","shell.execute_reply.started":"2024-08-18T14:13:51.702465Z","shell.execute_reply":"2024-08-18T14:13:51.71096Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"means = []\nstds = []\nfor img, _ in train_data:\n    means.append(torch.mean(img, [1, 2]).tolist())\n    stds.append(torch.std(img, [1, 2]).tolist())\n\nmean = torch.mean(torch.tensor(means), [0])\nstd = torch.mean(torch.tensor(stds), [0])\n\nmean, std","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:13:51.71338Z","iopub.execute_input":"2024-08-18T14:13:51.713824Z","iopub.status.idle":"2024-08-18T14:15:52.82333Z","shell.execute_reply.started":"2024-08-18T14:13:51.713661Z","shell.execute_reply":"2024-08-18T14:15:52.82221Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(tensor([1.2546, 0.8362, 0.5428]), tensor([1.1808, 1.3978, 1.5697]))"},"metadata":{}}]},{"cell_type":"code","source":"\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:15:52.824896Z","iopub.execute_input":"2024-08-18T14:15:52.825377Z","iopub.status.idle":"2024-08-18T14:15:52.832251Z","shell.execute_reply.started":"2024-08-18T14:15:52.825341Z","shell.execute_reply":"2024-08-18T14:15:52.831177Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 224, 224])"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 256\n\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\ntest_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:15:52.833415Z","iopub.execute_input":"2024-08-18T14:15:52.833733Z","iopub.status.idle":"2024-08-18T14:15:52.846318Z","shell.execute_reply.started":"2024-08-18T14:15:52.833689Z","shell.execute_reply":"2024-08-18T14:15:52.84516Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\nvgg19 = models.vgg19_bn(pretrained=True)\nvgg19","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:15:52.84755Z","iopub.execute_input":"2024-08-18T14:15:52.847891Z","iopub.status.idle":"2024-08-18T14:16:08.352581Z","shell.execute_reply.started":"2024-08-18T14:15:52.847864Z","shell.execute_reply":"2024-08-18T14:16:08.351617Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n100%|██████████| 548M/548M [00:13<00:00, 43.8MB/s] \n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nimport numpy as np\n\n\nclass TransferLearningClassifier(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        vgg = models.vgg19_bn(pretrained=True)\n       \n        for param in vgg.parameters():\n            param.requires_grad = False\n        \n        \n        in_features = vgg.classifier[0].in_features\n       \n        vgg.classifier = nn.Identity()\n     \n        self.feature_extractor = vgg\n        \n        self.dropout = nn.Dropout(0.2)\n        self.linear = nn.Linear(in_features, num_classes)\n        \n\n    def forward(self, x):\n        out = self.feature_extractor(x) # (batch, in_features)\n        \n        out = self.dropout(out)\n        out = self.linear(out)\n        \n        return out\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n            y_pred = F.softmax(self.forward(X), dim=-1)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = TransferLearningClassifier(len(dataset.classes)).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:16:08.356484Z","iopub.execute_input":"2024-08-18T14:16:08.356882Z","iopub.status.idle":"2024-08-18T14:16:10.444788Z","shell.execute_reply.started":"2024-08-18T14:16:08.356856Z","shell.execute_reply":"2024-08-18T14:16:10.443403Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:16:10.446103Z","iopub.execute_input":"2024-08-18T14:16:10.446429Z","iopub.status.idle":"2024-08-18T14:16:23.888752Z","shell.execute_reply.started":"2024-08-18T14:16:10.446401Z","shell.execute_reply":"2024-08-18T14:16:23.887358Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:16:23.89036Z","iopub.execute_input":"2024-08-18T14:16:23.890722Z","iopub.status.idle":"2024-08-18T14:16:24.714758Z","shell.execute_reply.started":"2024-08-18T14:16:23.890671Z","shell.execute_reply":"2024-08-18T14:16:24.713631Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n       BatchNorm2d-2         [-1, 64, 224, 224]             128\n              ReLU-3         [-1, 64, 224, 224]               0\n            Conv2d-4         [-1, 64, 224, 224]          36,928\n       BatchNorm2d-5         [-1, 64, 224, 224]             128\n              ReLU-6         [-1, 64, 224, 224]               0\n         MaxPool2d-7         [-1, 64, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]          73,856\n       BatchNorm2d-9        [-1, 128, 112, 112]             256\n             ReLU-10        [-1, 128, 112, 112]               0\n           Conv2d-11        [-1, 128, 112, 112]         147,584\n      BatchNorm2d-12        [-1, 128, 112, 112]             256\n             ReLU-13        [-1, 128, 112, 112]               0\n        MaxPool2d-14          [-1, 128, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         295,168\n      BatchNorm2d-16          [-1, 256, 56, 56]             512\n             ReLU-17          [-1, 256, 56, 56]               0\n           Conv2d-18          [-1, 256, 56, 56]         590,080\n      BatchNorm2d-19          [-1, 256, 56, 56]             512\n             ReLU-20          [-1, 256, 56, 56]               0\n           Conv2d-21          [-1, 256, 56, 56]         590,080\n      BatchNorm2d-22          [-1, 256, 56, 56]             512\n             ReLU-23          [-1, 256, 56, 56]               0\n           Conv2d-24          [-1, 256, 56, 56]         590,080\n      BatchNorm2d-25          [-1, 256, 56, 56]             512\n             ReLU-26          [-1, 256, 56, 56]               0\n        MaxPool2d-27          [-1, 256, 28, 28]               0\n           Conv2d-28          [-1, 512, 28, 28]       1,180,160\n      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n             ReLU-30          [-1, 512, 28, 28]               0\n           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n             ReLU-33          [-1, 512, 28, 28]               0\n           Conv2d-34          [-1, 512, 28, 28]       2,359,808\n      BatchNorm2d-35          [-1, 512, 28, 28]           1,024\n             ReLU-36          [-1, 512, 28, 28]               0\n           Conv2d-37          [-1, 512, 28, 28]       2,359,808\n      BatchNorm2d-38          [-1, 512, 28, 28]           1,024\n             ReLU-39          [-1, 512, 28, 28]               0\n        MaxPool2d-40          [-1, 512, 14, 14]               0\n           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n             ReLU-43          [-1, 512, 14, 14]               0\n           Conv2d-44          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-45          [-1, 512, 14, 14]           1,024\n             ReLU-46          [-1, 512, 14, 14]               0\n           Conv2d-47          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-48          [-1, 512, 14, 14]           1,024\n             ReLU-49          [-1, 512, 14, 14]               0\n           Conv2d-50          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-51          [-1, 512, 14, 14]           1,024\n             ReLU-52          [-1, 512, 14, 14]               0\n        MaxPool2d-53            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-54            [-1, 512, 7, 7]               0\n         Identity-55                [-1, 25088]               0\n              VGG-56                [-1, 25088]               0\n          Dropout-57                [-1, 25088]               0\n           Linear-58                   [-1, 33]         827,937\n================================================================\nTotal params: 20,863,329\nTrainable params: 827,937\nNon-trainable params: 20,035,392\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 352.38\nParams size (MB): 79.59\nEstimated Total Size (MB): 432.54\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n          metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n   \n\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n          (type(model).__name__, type(optimizer).__name__,\n           optimizer.param_groups[0]['lr'], epochs, device))\n\n    metrics = metrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n\n    history = {} \n    history['loss'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[name] = []\n        history[f'val_{name}'] = []\n\n    start_time_train = time.time()\n\n    for epoch in range(epochs):\n\n        \n        start_time_epoch = time.time()\n\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n\n        for batch in train_dl:\n            x    = batch[0].to(device)\n            y    = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            y_pred = y_pred.detach().cpu().numpy()\n            y = y.detach().cpu().numpy()\n\n\n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_ = y_pred.round()\n                    elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_train:\n            history_train[name] /= len(train_dl.dataset)\n\n\n        model.eval()\n        history_val = {'val_' + name: 0 for name in metrics_name+['loss']}\n\n        with torch.no_grad():\n            for batch in val_dl:\n                x    = batch[0].to(device)\n                y    = batch[1].to(device)\n                y_pred = model(x)\n                loss = loss_fn(y_pred, y)\n\n                y_pred = y_pred.cpu().numpy()\n                y = y.cpu().numpy()\n\n                history_val['val_loss'] += loss.item() * x.size(0)\n                for name, func in zip(metrics_name, metrics):\n                    try:\n                        history_val['val_'+name] += func(y, y_pred) * x.size(0)\n                    except:\n                        if task == 'binary': y_pred_ = y_pred.round()\n                        elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n\n                        history_val['val_'+name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_val:\n            history_val[name] /= len(val_dl.dataset)\n\n      \n\n        end_time_epoch = time.time()\n\n        for name in history_train:\n            history[name].append(history_train[name])\n            history['val_'+name].append(history_val['val_'+name])\n\n        total_time_epoch = end_time_epoch - start_time_epoch\n\n        print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n        for name in history_train:\n            print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n            print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n        print()\n\n  \n\n    end_time_train       = time.time()\n    total_time_train     = end_time_train - start_time_train\n    print()\n    print('Time total:     %5.2f sec' % (total_time_train))\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:16:24.716224Z","iopub.execute_input":"2024-08-18T14:16:24.716546Z","iopub.status.idle":"2024-08-18T14:16:24.734837Z","shell.execute_reply.started":"2024-08-18T14:16:24.716516Z","shell.execute_reply":"2024-08-18T14:16:24.733836Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:16:24.736018Z","iopub.execute_input":"2024-08-18T14:16:24.736377Z","iopub.status.idle":"2024-08-18T14:16:24.750575Z","shell.execute_reply.started":"2024-08-18T14:16:24.73635Z","shell.execute_reply":"2024-08-18T14:16:24.749667Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, test_loader,\n                epochs=50,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-08-18T14:16:24.751875Z","iopub.execute_input":"2024-08-18T14:16:24.752601Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"train() called: model=TransferLearningClassifier, opt=Adam(lr=0.000100), epochs=50, device=cpu\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_metric(history, name):\n    plt.title(f\"Model results with {name}\")\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()\n\n\nplot_metric(history, 'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}